{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Printing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "vscode": {
     "languageId": "java"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chart saved as image: jfreechart_example.png\n"
     ]
    }
   ],
   "source": [
    "%maven org.jfree:jfreechart:1.5.3\n",
    "%maven com.opencsv:opencsv:5.5\n",
    "import org.jfree.chart.ChartFactory;\n",
    "import org.jfree.chart.ChartUtils;\n",
    "import org.jfree.chart.JFreeChart;\n",
    "import org.jfree.data.category.CategoryDataset;\n",
    "import org.jfree.data.category.DefaultCategoryDataset;\n",
    "import com.opencsv.CSVReader;\n",
    "import java.io.File;\n",
    "import java.io.IOException;\n",
    "import java.io.FileReader;\n",
    "\n",
    "public class JFreeChartExample {\n",
    "\n",
    "    public static CategoryDataset createDataset() {\n",
    "        DefaultCategoryDataset dataset = new DefaultCategoryDataset();\n",
    "        \n",
    "\n",
    "        dataset.addValue(1.0, \"Series1\", \"Category1\");\n",
    "        dataset.addValue(4.0, \"Series1\", \"Category2\");\n",
    "        dataset.addValue(3.0, \"Series1\", \"Category3\");\n",
    "        dataset.addValue(5.0, \"Series1\", \"Category4\");\n",
    "\n",
    "        return dataset;\n",
    "    }\n",
    "\n",
    "    public static JFreeChart createChart(CategoryDataset dataset) {\n",
    "        return ChartFactory.createLineChart(\n",
    "                \"JFreeChart Example\",\n",
    "                \"Category\",\n",
    "                \"Value\",\n",
    "                dataset\n",
    "        );\n",
    "    }\n",
    "\n",
    "    public static void saveChartAsImage(JFreeChart chart, String filePath, int width, int height) throws IOException {\n",
    "        ChartUtils.saveChartAsPNG(new File(filePath), chart, width, height);\n",
    "    }\n",
    "\n",
    "    public static void main(String[] args) {\n",
    "        try {\n",
    "            String[] tickers = [\"AAPL\", \"AMZN\", \"COST\", \"GOOGL\", \"LMT\", \"META\", \"MSFT\", \"NOC\", \"TSLA\", \"UNH\", \"WMT\"]\n",
    "            for (String ticker : tickers) {\n",
    "                CategoryDataset dataset = createDataset();\n",
    "                JFreeChart chart = createChart(dataset);\n",
    "                String chartname = \"./stock_charts/\" + tickers;\n",
    "\n",
    "                // Save chart as image\n",
    "                saveChartAsImage(chart, \"./jfreechart_example.png\", 800, 600);\n",
    "\n",
    "                System.out.println(\"Chart saved as image: jfreechart_example.png\");\n",
    "            }\n",
    "            \n",
    "        } catch (IOException e) {\n",
    "            e.printStackTrace();\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "JFreeChartExample.main(null);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing code for LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "java"
    }
   },
   "outputs": [],
   "source": [
    "%maven org.deeplearning4j:deeplearning4j-core:1.0.0-M2.1\n",
    "%maven org.nd4j:nd4j-native:1.0.0-M2.1\n",
    "\n",
    "import org.deeplearning4j.datasets.iterator.impl.*;\n",
    "import org.deeplearning4j.nn.api.OptimizationAlgorithm;\n",
    "import org.deeplearning4j.nn.conf.GradientNormalization;\n",
    "import org.deeplearning4j.nn.conf.NeuralNetConfiguration;\n",
    "import org.deeplearning4j.nn.conf.layers.LSTM;\n",
    "import org.deeplearning4j.nn.conf.layers.RnnOutputLayer;\n",
    "import org.deeplearning4j.nn.multilayer.MultiLayerNetwork;\n",
    "import org.deeplearning4j.nn.weights.WeightInit;\n",
    "import org.deeplearning4j.optimize.listeners.ScoreIterationListener;\n",
    "import org.nd4j.linalg.activations.Activation;\n",
    "import org.nd4j.linalg.dataset.api.iterator.DataSetIterator;\n",
    "import org.nd4j.linalg.learning.config.Adam;\n",
    "import org.nd4j.linalg.lossfunctions.LossFunctions;\n",
    "import java.util.ArrayList;\n",
    "import java.util.List;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "java"
    }
   },
   "outputs": [
    {
     "ename": "CompilationException",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30mpublic class LstmExample {\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m    public static void main(String[] args) {\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m        // Define your dataset and load it\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m        // Example: List<double[]> features = loadFeatures();\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m        // List<double[]> labels = loadLabels();\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m        // Create DataSetIterator\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m        DataSetIterator iterator = new ListDataSetIterator<>(createData(features, labels));\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m        // Neural network configuration\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m        MultiLayerNetwork model = new MultiLayerNetwork(new NeuralNetConfiguration.Builder()\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m                .seed(123)\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m                .optimizationAlgo(OptimizationAlgorithm.STOCHASTIC_GRADIENT_DESCENT)\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m                .updater(new Adam(0.01))\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m                .l2(1e-4)\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m                .weightInit(WeightInit.XAVIER)\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m                .gradientNormalization(GradientNormalization.ClipElementWiseAbsoluteValue)\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m                .gradientNormalizationThreshold(0.5)\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m                .list()\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m                .layer(new LSTM.Builder()\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m                        .nIn(numInputs)\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m                        .nOut(numHiddenUnits)\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m                        .activation(Activation.TANH)\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m                        .build())\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m                .layer(new RnnOutputLayer.Builder(LossFunctions.LossFunction.MSE)\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m                        .activation(Activation.IDENTITY)\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m                        .nIn(numHiddenUnits)\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m                        .nOut(numOutputs)\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m                        .build())\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m                .pretrain(false)\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m                .backprop(true)\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m                .build()\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m        );\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m        model.init();\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m        model.setListeners(new ScoreIterationListener(20));  // Print the score with every 20 iterations\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m        // Train the model\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m        int numEpochs = 50;\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m        for (int i = 0; i < numEpochs; i++) {\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m            model.fit(iterator);\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m        }\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m        // Your model is now trained and ready for prediction\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m    }\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m    private static List<DataSet> createData(List<double[]> features, List<double[]> labels) {\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m        List<DataSet> dataSets = new ArrayList<>();\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m        for (int i = 0; i < features.size(); i++) {\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m            dataSets.add(new DataSet(Nd4j.create(features.get(i)), Nd4j.create(labels.get(i))));\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m        }\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m        return dataSets;\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m    }\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m    // Implement methods to load your features and labels from your dataset\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m    // private static List<double[]> loadFeatures() { ... }\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m    // private static List<double[]> loadLabels() { ... }\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m}\u001b[0m",
      "\u001b[1m\u001b[31mUnresolved dependencies:\u001b[0m",
      "\u001b[1m\u001b[31m   - class DataSet\u001b[0m",
      "\u001b[1m\u001b[31m   - class ListDataSetIterator\u001b[0m",
      "\u001b[1m\u001b[31m   - variable features\u001b[0m",
      "\u001b[1m\u001b[31m   - variable labels\u001b[0m",
      "\u001b[1m\u001b[31m   - variable numHiddenUnits\u001b[0m",
      "\u001b[1m\u001b[31m   - variable numInputs\u001b[0m",
      "\u001b[1m\u001b[31m   - variable numOutputs\u001b[0m",
      "\u001b[1m\u001b[31m   - variable Nd4j\u001b[0m"
     ]
    }
   ],
   "source": [
    "public class LstmExample {\n",
    "\n",
    "    public static void main(String[] args) {\n",
    "        // Define your dataset and load it\n",
    "        // Example: List<double[]> features = loadFeatures();\n",
    "        // List<double[]> labels = loadLabels();\n",
    "\n",
    "        // Create DataSetIterator\n",
    "        DataSetIterator iterator = new ListDataSetIterator<>(createData(features, labels));\n",
    "\n",
    "        // Neural network configuration\n",
    "        MultiLayerNetwork model = new MultiLayerNetwork(new NeuralNetConfiguration.Builder()\n",
    "                .seed(123)\n",
    "                .optimizationAlgo(OptimizationAlgorithm.STOCHASTIC_GRADIENT_DESCENT)\n",
    "                .updater(new Adam(0.01))\n",
    "                .l2(1e-4)\n",
    "                .weightInit(WeightInit.XAVIER)\n",
    "                .gradientNormalization(GradientNormalization.ClipElementWiseAbsoluteValue)\n",
    "                .gradientNormalizationThreshold(0.5)\n",
    "                .list()\n",
    "                .layer(new LSTM.Builder()\n",
    "                        .nIn(numInputs)\n",
    "                        .nOut(numHiddenUnits)\n",
    "                        .activation(Activation.TANH)\n",
    "                        .build())\n",
    "                .layer(new RnnOutputLayer.Builder(LossFunctions.LossFunction.MSE)\n",
    "                        .activation(Activation.IDENTITY)\n",
    "                        .nIn(numHiddenUnits)\n",
    "                        .nOut(numOutputs)\n",
    "                        .build())\n",
    "                .pretrain(false)\n",
    "                .backprop(true)\n",
    "                .build()\n",
    "        );\n",
    "\n",
    "        model.init();\n",
    "        model.setListeners(new ScoreIterationListener(20));  // Print the score with every 20 iterations\n",
    "\n",
    "        // Train the model\n",
    "        int numEpochs = 50;\n",
    "        for (int i = 0; i < numEpochs; i++) {\n",
    "            model.fit(iterator);\n",
    "        }\n",
    "\n",
    "        // Your model is now trained and ready for prediction\n",
    "    }\n",
    "\n",
    "    private static List<DataSet> createData(List<double[]> features, List<double[]> labels) {\n",
    "        List<DataSet> dataSets = new ArrayList<>();\n",
    "        for (int i = 0; i < features.size(); i++) {\n",
    "            dataSets.add(new DataSet(Nd4j.create(features.get(i)), Nd4j.create(labels.get(i))));\n",
    "        }\n",
    "        return dataSets;\n",
    "    }\n",
    "\n",
    "    // Implement methods to load your features and labels from your dataset\n",
    "    // private static List<double[]> loadFeatures() { ... }\n",
    "    // private static List<double[]> loadLabels() { ... }\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "java",
   "language": "java",
   "name": "java"
  },
  "language_info": {
   "codemirror_mode": "java",
   "file_extension": ".jshell",
   "mimetype": "text/x-java-source",
   "name": "Java",
   "pygments_lexer": "java",
   "version": "17.0.9+9-Ubuntu-120.04"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

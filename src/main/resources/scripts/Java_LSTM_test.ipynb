{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viewing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chart saved as image: ./stock_charts/date_vs_volume/AAPL_chart.png\n",
      "Chart saved as image: ./stock_charts/date_vs_volume/AMZN_chart.png\n",
      "Chart saved as image: ./stock_charts/date_vs_volume/COST_chart.png\n",
      "Chart saved as image: ./stock_charts/date_vs_volume/GOOGL_chart.png\n",
      "Chart saved as image: ./stock_charts/date_vs_volume/LMT_chart.png\n",
      "Chart saved as image: ./stock_charts/date_vs_volume/META_chart.png\n",
      "Chart saved as image: ./stock_charts/date_vs_volume/MSFT_chart.png\n",
      "Chart saved as image: ./stock_charts/date_vs_volume/NOC_chart.png\n",
      "Chart saved as image: ./stock_charts/date_vs_volume/TSLA_chart.png\n",
      "Chart saved as image: ./stock_charts/date_vs_volume/UNH_chart.png\n",
      "Chart saved as image: ./stock_charts/date_vs_volume/WMT_chart.png\n"
     ]
    }
   ],
   "source": [
    "%maven org.jfree:jfreechart:1.5.3\n",
    "%maven com.opencsv:opencsv:5.5\n",
    "import org.jfree.chart.ChartFactory;\n",
    "import org.jfree.chart.ChartUtils;\n",
    "import org.jfree.chart.JFreeChart;\n",
    "import org.jfree.data.category.CategoryDataset;\n",
    "import org.jfree.data.category.DefaultCategoryDataset;\n",
    "import java.io.File;\n",
    "import java.io.BufferedReader;  \n",
    "import java.io.IOException;\n",
    "import java.io.FileReader;\n",
    "\n",
    "public class JFreeChartExample {\n",
    "\n",
    "    public static CategoryDataset createDataset(String ticker){\n",
    "        DefaultCategoryDataset dataset = new DefaultCategoryDataset();\n",
    "        String csvFilePath = \"./stock_data/\" + ticker + \".csv\";\n",
    "        try (BufferedReader br = new BufferedReader(new FileReader(csvFilePath))) {\n",
    "            int dateColumnIndex = 0;\n",
    "            int closeColumnIndex = 6;\n",
    "            String line = br.readLine();  \n",
    "            while ((line = br.readLine()) != null) {\n",
    "                String[] data = line.split(\",\");\n",
    "                String date = data[dateColumnIndex];\n",
    "                Double close = Double.parseDouble(data[closeColumnIndex]);\n",
    "                dataset.addValue(close, ticker, date);\n",
    "            }\n",
    "        } catch (IOException e) {\n",
    "            e.printStackTrace();\n",
    "        }\n",
    "\n",
    "        return dataset;\n",
    "    }\n",
    "\n",
    "    public static JFreeChart createChart(CategoryDataset dataset, String ticker, String val1, String val2) {\n",
    "        String title = val1 + \" vs. \" + val2 + \" for \" + ticker;\n",
    "        return ChartFactory.createLineChart(\n",
    "                title,\n",
    "                val1,\n",
    "                val2,\n",
    "                dataset\n",
    "        );\n",
    "    }\n",
    "\n",
    "    public static void saveChartAsImage(JFreeChart chart, String filePath, int width, int height) throws IOException {\n",
    "        ChartUtils.saveChartAsPNG(new File(filePath), chart, width, height);\n",
    "    }\n",
    "\n",
    "    public static void main(String[] args) {\n",
    "        try {\n",
    "            String[] tickers = {\"AAPL\", \"AMZN\", \"COST\", \"GOOGL\", \"LMT\", \"META\", \"MSFT\", \"NOC\", \"TSLA\", \"UNH\", \"WMT\"};\n",
    "            for (String ticker : tickers) {\n",
    "                CategoryDataset dataset = createDataset(ticker);\n",
    "                JFreeChart chart = createChart(dataset, ticker, \"Date\", \"Volume\");\n",
    "                String chartname = \"./stock_charts/date_vs_volume/\" + ticker + \"_chart.png\";\n",
    "\n",
    "                // Save chart as image\n",
    "                saveChartAsImage(chart, chartname, 800, 600);\n",
    "\n",
    "                System.out.println(\"Chart saved as image: \" + chartname);\n",
    "            }\n",
    "            \n",
    "        } catch (IOException e) {\n",
    "            e.printStackTrace();\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "JFreeChartExample.main(null);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create testing and training datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%maven org.nd4j:nd4j-native-platform:1.0.0-beta2\n",
    "%maven org.deeplearning4j:deeplearning4j-core:1.0.0-beta2\n",
    "%maven org.deeplearning4j:deeplearning4j-ui_2.11:1.0.0-beta2\n",
    "%maven ch.qos.logback:logback-classic:1.2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "EvalException",
     "evalue": "Could not initialize class org.nd4j.linalg.factory.Nd4j",
     "output_type": "error",
     "traceback": [
      "\u001b[1m\u001b[31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1m\u001b[31mjava.lang.NoClassDefFoundError: Could not initialize class org.nd4j.linalg.factory.Nd4j\u001b[0m",
      "\u001b[1m\u001b[31m\tat DatasetCreator.createScaledData(#41:1)\u001b[0m",
      "\u001b[1m\u001b[31m\tat DatasetCreator.main(#41:1)\u001b[0m",
      "\u001b[1m\u001b[31m\tat .(#78:1)\u001b[0m"
     ]
    }
   ],
   "source": [
    "import java.util.ArrayList;\n",
    "import org.nd4j.linalg.api.ndarray.INDArray;\n",
    "import org.nd4j.linalg.dataset.api.iterator.DataSetIterator;\n",
    "import org.nd4j.linalg.dataset.api.iterator.StandardScaler;\n",
    "import org.nd4j.linalg.factory.Nd4j;\n",
    "import org.nd4j.linalg.dataset.api.preprocessor.NormalizerMinMaxScaler;\n",
    "\n",
    "public class DatasetCreator {\n",
    "    String ticker;\n",
    "    String tickerPath;\n",
    "    \n",
    "    public DatasetCreator(String ticker) {\n",
    "        this.ticker = ticker;\n",
    "        this.tickerPath = \"./stock_data/\" + this.ticker + \".csv\";\n",
    "    }\n",
    "\n",
    "    private double[] extractCSVCloseData(){\n",
    "        ArrayList<Double> CSVData = new ArrayList<Double>();\n",
    "        try (BufferedReader br = new BufferedReader(new FileReader(this.tickerPath))) {\n",
    "            int closeColumnIndex = 4;\n",
    "            String line = br.readLine();  \n",
    "            while ((line = br.readLine()) != null) {\n",
    "                String[] data = line.split(\",\");\n",
    "                CSVData.add(Double.parseDouble(data[closeColumnIndex]));\n",
    "            }\n",
    "        } catch (IOException e) {\n",
    "            e.printStackTrace();\n",
    "        }\n",
    "\n",
    "        double[] CSVDataArray = new double[CSVData.size()];\n",
    "        for (int i = 0; i < CSVData.size(); i++) {\n",
    "            CSVDataArray[i] = CSVData.get(i);\n",
    "        }\n",
    "\n",
    "        return CSVDataArray;\n",
    "    }\n",
    "\n",
    "    private INDArray createScaledData() {\n",
    "        double[] CSVDataArray = this.extractCSVCloseData();\n",
    "        INDArray data = Nd4j.create(CSVDataArray);\n",
    "        // NormalizerMinMaxScaler scaler = new NormalizerMinMaxScaler(0, 1);\n",
    "        // scaler.fit(data);\n",
    "        // INDArray scaledData = scaler.transform(data);\n",
    "        return data;\n",
    "    }\n",
    "\n",
    "    public void main(String args[]) {\n",
    "        INDArray scaledData = createScaledData();\n",
    "        System.out.println(scaledData);\n",
    "    }\n",
    "}\n",
    "\n",
    "DatasetCreator test = new DatasetCreator(\"AAPL\");\n",
    "test.main(null);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing code for LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.deeplearning4j.datasets.iterator.impl.*;\n",
    "import org.deeplearning4j.nn.api.OptimizationAlgorithm;\n",
    "import org.deeplearning4j.nn.conf.GradientNormalization;\n",
    "import org.deeplearning4j.nn.conf.NeuralNetConfiguration;\n",
    "import org.deeplearning4j.nn.conf.layers.LSTM;\n",
    "import org.deeplearning4j.nn.conf.layers.RnnOutputLayer;\n",
    "import org.deeplearning4j.nn.multilayer.MultiLayerNetwork;\n",
    "import org.deeplearning4j.nn.weights.WeightInit;\n",
    "import org.deeplearning4j.optimize.listeners.ScoreIterationListener;\n",
    "import org.nd4j.linalg.activations.Activation;\n",
    "import org.nd4j.linalg.dataset.api.iterator.DataSetIterator;\n",
    "import org.nd4j.linalg.learning.config.Adam;\n",
    "import org.nd4j.linalg.lossfunctions.LossFunctions;\n",
    "import java.util.ArrayList;\n",
    "import java.util.List;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "CompilationException",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30mpublic class LstmExample {\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m    public static void main(String[] args) {\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m        // Define your dataset and load it\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m        // Example: List<double[]> features = loadFeatures();\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m        // List<double[]> labels = loadLabels();\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m        // Create DataSetIterator\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m        DataSetIterator iterator = new ListDataSetIterator<>(createData(features, labels));\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m        // Neural network configuration\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m        MultiLayerNetwork model = new MultiLayerNetwork(new NeuralNetConfiguration.Builder()\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m                .seed(123)\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m                .optimizationAlgo(OptimizationAlgorithm.STOCHASTIC_GRADIENT_DESCENT)\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m                .updater(new Adam(0.01))\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m                .l2(1e-4)\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m                .weightInit(WeightInit.XAVIER)\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m                .gradientNormalization(GradientNormalization.ClipElementWiseAbsoluteValue)\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m                .gradientNormalizationThreshold(0.5)\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m                .list()\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m                .layer(new LSTM.Builder()\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m                        .nIn(numInputs)\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m                        .nOut(numHiddenUnits)\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m                        .activation(Activation.TANH)\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m                        .build())\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m                .layer(new RnnOutputLayer.Builder(LossFunctions.LossFunction.MSE)\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m                        .activation(Activation.IDENTITY)\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m                        .nIn(numHiddenUnits)\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m                        .nOut(numOutputs)\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m                        .build())\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m                .pretrain(false)\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m                .backprop(true)\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m                .build()\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m        );\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m        model.init();\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m        model.setListeners(new ScoreIterationListener(20));  // Print the score with every 20 iterations\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m        // Train the model\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m        int numEpochs = 50;\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m        for (int i = 0; i < numEpochs; i++) {\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m            model.fit(iterator);\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m        }\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m        // Your model is now trained and ready for prediction\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m    }\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m    private static List<DataSet> createData(List<double[]> features, List<double[]> labels) {\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m        List<DataSet> dataSets = new ArrayList<>();\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m        for (int i = 0; i < features.size(); i++) {\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m            dataSets.add(new DataSet(Nd4j.create(features.get(i)), Nd4j.create(labels.get(i))));\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m        }\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m        return dataSets;\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m    }\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m    // Implement methods to load your features and labels from your dataset\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m    // private static List<double[]> loadFeatures() { ... }\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m    // private static List<double[]> loadLabels() { ... }\u001b[0m",
      "\u001b[1m\u001b[30m|   \u001b[1m\u001b[30m}\u001b[0m",
      "\u001b[1m\u001b[31mUnresolved dependencies:\u001b[0m",
      "\u001b[1m\u001b[31m   - class DataSet\u001b[0m",
      "\u001b[1m\u001b[31m   - class ListDataSetIterator\u001b[0m",
      "\u001b[1m\u001b[31m   - variable features\u001b[0m",
      "\u001b[1m\u001b[31m   - variable labels\u001b[0m",
      "\u001b[1m\u001b[31m   - variable numHiddenUnits\u001b[0m",
      "\u001b[1m\u001b[31m   - variable numInputs\u001b[0m",
      "\u001b[1m\u001b[31m   - variable numOutputs\u001b[0m",
      "\u001b[1m\u001b[31m   - variable Nd4j\u001b[0m"
     ]
    }
   ],
   "source": [
    "public class LstmExample {\n",
    "\n",
    "    public static void main(String[] args) {\n",
    "        // Define your dataset and load it\n",
    "        // Example: List<double[]> features = loadFeatures();\n",
    "        // List<double[]> labels = loadLabels();\n",
    "\n",
    "        // Create DataSetIterator\n",
    "        DataSetIterator iterator = new ListDataSetIterator<>(createData(features, labels));\n",
    "\n",
    "        // Neural network configuration\n",
    "        MultiLayerNetwork model = new MultiLayerNetwork(new NeuralNetConfiguration.Builder()\n",
    "                .seed(123)\n",
    "                .optimizationAlgo(OptimizationAlgorithm.STOCHASTIC_GRADIENT_DESCENT)\n",
    "                .updater(new Adam(0.01))\n",
    "                .l2(1e-4)\n",
    "                .weightInit(WeightInit.XAVIER)\n",
    "                .gradientNormalization(GradientNormalization.ClipElementWiseAbsoluteValue)\n",
    "                .gradientNormalizationThreshold(0.5)\n",
    "                .list()\n",
    "                .layer(new LSTM.Builder()\n",
    "                        .nIn(numInputs)\n",
    "                        .nOut(numHiddenUnits)\n",
    "                        .activation(Activation.TANH)\n",
    "                        .build())\n",
    "                .layer(new RnnOutputLayer.Builder(LossFunctions.LossFunction.MSE)\n",
    "                        .activation(Activation.IDENTITY)\n",
    "                        .nIn(numHiddenUnits)\n",
    "                        .nOut(numOutputs)\n",
    "                        .build())\n",
    "                .pretrain(false)\n",
    "                .backprop(true)\n",
    "                .build()\n",
    "        );\n",
    "\n",
    "        model.init();\n",
    "        model.setListeners(new ScoreIterationListener(20));  // Print the score with every 20 iterations\n",
    "\n",
    "        // Train the model\n",
    "        int numEpochs = 50;\n",
    "        for (int i = 0; i < numEpochs; i++) {\n",
    "            model.fit(iterator);\n",
    "        }\n",
    "\n",
    "        // Your model is now trained and ready for prediction\n",
    "    }\n",
    "\n",
    "    private static List<DataSet> createData(List<double[]> features, List<double[]> labels) {\n",
    "        List<DataSet> dataSets = new ArrayList<>();\n",
    "        for (int i = 0; i < features.size(); i++) {\n",
    "            dataSets.add(new DataSet(Nd4j.create(features.get(i)), Nd4j.create(labels.get(i))));\n",
    "        }\n",
    "        return dataSets;\n",
    "    }\n",
    "\n",
    "    // Implement methods to load your features and labels from your dataset\n",
    "    // private static List<double[]> loadFeatures() { ... }\n",
    "    // private static List<double[]> loadLabels() { ... }\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "java",
   "language": "java",
   "name": "java"
  },
  "language_info": {
   "codemirror_mode": "java",
   "file_extension": ".jshell",
   "mimetype": "text/x-java-source",
   "name": "java",
   "pygments_lexer": "java",
   "version": "11.0.21+9-post-Ubuntu-0ubuntu122.04"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
